# Variance of the Ws.
hist(apply(ws[[1]], c(2, 3), mean))
hypers$lambda_frac
# Variance of the Ws.
hist(apply(ws[[1]], c(2, 3), var))
hypers$lambda_frac
Vstar <- 1
AVstar <- 0.1
K <- 2
tensor_dim <- c(10, 20)
D <- 6
alpha <- 1
a_lambda <- 30
a_tau <- 30
a_sigma <- 30
hypers <- GetHyper(K = K, D = D, Vstar = Vstar, AVstar = AVstar, alpha = alpha,
a_lambda = a_lambda, a_tau = a_tau, a_sigma = a_sigma,
include_C = TRUE)
hypers$lambda_frac
a_lambda <- 10
a_tau <- 30
a_sigma <- 30
hypers <- GetHyper(K = K, D = D, Vstar = Vstar, AVstar = AVstar, alpha = alpha,
a_lambda = a_lambda, a_tau = a_tau, a_sigma = a_sigma,
include_C = TRUE)
hypers$lambda_frac
source('~/Github/SofTeR/R/GetHyper_function.R')
Vstar <- 1
AVstar <- 0.1
K <- 2
tensor_dim <- c(10, 20)
D <- 6
alpha <- 1
a_lambda <- 10
a_tau <- 30
a_sigma <- 30
hypers <- GetHyper(K = K, D = D, Vstar = Vstar, AVstar = AVstar, alpha = alpha,
a_lambda = a_lambda, a_tau = a_tau, a_sigma = a_sigma,
include_C = TRUE)
b_tau <- hypers$b_tau
b_sigma <- hypers$b_sigma
b_lambda <- hypers$b_lambda
Nsims <- 2000
B_entries <- array(NA, dim = c(Nsims, tensor_dim))
parafac <- array(NA, dim = c(Nsims, tensor_dim))
zetas <- matrix(NA, Nsims, D)
ws <- NULL
ws[[1]] <- array(NA, dim = c(Nsims, tensor_dim[1], D))
ws[[2]] <- array(NA, dim = c(Nsims, tensor_dim[2], D))
for (ss in 1 : Nsims) {
zetas[ss, ] <- DirichletReg::rdirichlet(1, rep(alpha / D, D))
sigmas <- MCMCpack::rinvgamma(K, a_sigma, b_sigma)
tau_gamma <- rgamma(1, shape = a_tau, rate = b_tau)
lambdas <- matrix(rgamma(n = K * D, shape = a_lambda, rate = b_lambda), K, D)
gammas <- NULL
for (kk in 1 : K) {
ws[[kk]][ss, , ] <- rexp(tensor_dim[kk] * D,
rep(lambdas[kk, ] ^ 2, each = tensor_dim[kk]))
gamma_var <- ws[[kk]][ss, , ] * tau_gamma
gamma_var <- sweep(gamma_var, 2, zetas[ss, ], FUN = '*')
gammas[[kk]] <- matrix(rnorm(tensor_dim[kk] * D, sd = sqrt(gamma_var)), tensor_dim[kk], D)
}
Bs <- array(NA, dim = c(K, tensor_dim, D))
for (dd in 1 : D) {
for (jk in 1 : tensor_dim[1]) {
Bs[1, jk, , dd] <- rnorm(prod(tensor_dim[- 1]), mean = gammas[[1]][jk, dd],
sd = sqrt(sigmas[kk] * zetas[ss, dd]))
Bs[2, , jk, dd] <- rnorm(prod(tensor_dim[- 2]), mean = gammas[[2]][jk, dd],
sd = sqrt(sigmas[2] * zetas[ss, dd]))
}
}
final_B <- apply(Bs, c(2, 3, 4), prod)
final_B <- apply(final_B, c(1, 2), sum)
B_entries[ss, , ] <- final_B
this_parafac <- outer(gammas[[1]][, 1], gammas[[2]][, 1])
if (D > 1) {
for (dd in 2 : D) {
this_parafac <- this_parafac + outer(gammas[[1]][, dd], gammas[[2]][, dd])
}
}
parafac[ss, , ] <- this_parafac
}
hist(apply(B_entries, c(2, 3), var), breaks = 100)
hist(apply(parafac, c(2, 3), var), breaks = 100)
hist((apply(B_entries, c(2, 3), var) - apply(parafac, c(2, 3), var)) /
apply(B_entries, c(2, 3), sd), breaks = 100)
# Simulating the B gives me the correct AV but the wrong variance.
#
# I will check whether the analytic calculation of my variance gives me Vstar
# or the simulated one.
analyt_var <- (b_sigma / (a_sigma - 1)) ^ K
for (ll in 1 : K) {
rho <- a_tau
if (ll > 1) {
for (rr in 2 : ll) {
rho <- rho * (a_tau + rr - 1)
}
}
bin <- factorial(K) / (factorial(ll) * factorial(K - ll))
add_on <- bin * rho / (b_tau ^ ll)
add_on <- add_on * hypers$lambda_frac ^ ll * (b_sigma / (a_sigma - 1)) ^ (K - ll)
analyt_var <- analyt_var + add_on
}
analyt_var <- analyt_var * hypers$C
analyt_var
# Variance of zeta to the K -- C
apply(zetas ^ K, 2, mean) * D
hypers$C
# Variance of the Ws.
hist(apply(ws[[1]], c(2, 3), var))
hypers$lambda_frac
hist(unlist(ws))
hist(unlist(ws), xlim = c(0, 2))
hist(unlist(ws), xlim = c(0, 2), breaks = 1000)
xxx <- 3
hist(rexp(100000, rate = xxx))
source('~/Github/SofTeR/R/GetHyper_function.R')
Vstar <- 1
AVstar <- 0.1
K <- 2
tensor_dim <- c(10, 20)
D <- 6
alpha <- 1
a_lambda <- 10
a_tau <- 30
a_sigma <- 30
hypers <- GetHyper(K = K, D = D, Vstar = Vstar, AVstar = AVstar, alpha = alpha,
a_lambda = a_lambda, a_tau = a_tau, a_sigma = a_sigma,
include_C = TRUE)
b_tau <- hypers$b_tau
b_sigma <- hypers$b_sigma
b_lambda <- hypers$b_lambda
Nsims <- 2000
B_entries <- array(NA, dim = c(Nsims, tensor_dim))
parafac <- array(NA, dim = c(Nsims, tensor_dim))
zetas <- matrix(NA, Nsims, D)
ws <- NULL
ws[[1]] <- array(NA, dim = c(Nsims, tensor_dim[1], D))
ws[[2]] <- array(NA, dim = c(Nsims, tensor_dim[2], D))
for (ss in 1 : Nsims) {
zetas[ss, ] <- DirichletReg::rdirichlet(1, rep(alpha / D, D))
sigmas <- MCMCpack::rinvgamma(K, a_sigma, b_sigma)
tau_gamma <- rgamma(1, shape = a_tau, rate = b_tau)
lambdas <- matrix(rgamma(n = K * D, shape = a_lambda, rate = b_lambda), K, D)
gammas <- NULL
for (kk in 1 : K) {
exp_rate <- rep(lambdas[kk, ] ^ 2 / 2, each = tensor_dim[kk])
ws[[kk]][ss, , ] <- rexp(tensor_dim[kk] * D, exp_rate)
gamma_var <- ws[[kk]][ss, , ] * tau_gamma
gamma_var <- sweep(gamma_var, 2, zetas[ss, ], FUN = '*')
gammas[[kk]] <- matrix(rnorm(tensor_dim[kk] * D, sd = sqrt(gamma_var)), tensor_dim[kk], D)
}
Bs <- array(NA, dim = c(K, tensor_dim, D))
for (dd in 1 : D) {
for (jk in 1 : tensor_dim[1]) {
Bs[1, jk, , dd] <- rnorm(prod(tensor_dim[- 1]), mean = gammas[[1]][jk, dd],
sd = sqrt(sigmas[kk] * zetas[ss, dd]))
Bs[2, , jk, dd] <- rnorm(prod(tensor_dim[- 2]), mean = gammas[[2]][jk, dd],
sd = sqrt(sigmas[2] * zetas[ss, dd]))
}
}
final_B <- apply(Bs, c(2, 3, 4), prod)
final_B <- apply(final_B, c(1, 2), sum)
B_entries[ss, , ] <- final_B
this_parafac <- outer(gammas[[1]][, 1], gammas[[2]][, 1])
if (D > 1) {
for (dd in 2 : D) {
this_parafac <- this_parafac + outer(gammas[[1]][, dd], gammas[[2]][, dd])
}
}
parafac[ss, , ] <- this_parafac
}
hist(apply(B_entries, c(2, 3), var), breaks = 100)
hist(apply(parafac, c(2, 3), var), breaks = 100)
hist((apply(B_entries, c(2, 3), var) - apply(parafac, c(2, 3), var)) /
apply(B_entries, c(2, 3), sd), breaks = 100)
hist(apply(B_entries, c(2, 3), var), breaks = 100)
abline(v = Vstar, col = 'red')
abline(v = Vstar, col = 'red', lwd = 3)
hist(apply(parafac, c(2, 3), var), breaks = 100)
hist((apply(B_entries, c(2, 3), var) - apply(parafac, c(2, 3), var)) /
apply(B_entries, c(2, 3), sd), breaks = 100)
abline(v = AVstar, col = 'red', lwd = 3)
analyt_var <- (b_sigma / (a_sigma - 1)) ^ K
for (ll in 1 : K) {
rho <- a_tau
if (ll > 1) {
for (rr in 2 : ll) {
rho <- rho * (a_tau + rr - 1)
}
}
bin <- factorial(K) / (factorial(ll) * factorial(K - ll))
add_on <- bin * rho / (b_tau ^ ll)
add_on <- add_on * hypers$lambda_frac ^ ll * (b_sigma / (a_sigma - 1)) ^ (K - ll)
analyt_var <- analyt_var + add_on
}
analyt_var <- analyt_var * hypers$C
analyt_var
# Variance of zeta to the K -- C
apply(zetas ^ K, 2, mean) * D
hypers$C
# Variance of the Ws.
hist(apply(ws[[1]], c(2, 3), var))
hypers$lambda_frac
# Variance of the Ws.
hist(apply(ws[[2]], c(2, 3), var))
# Variance of the Ws.
hist(apply(ws[[2]], c(2, 3), mean))
hypers$lambda_frac
abline(v = hypers$lambda_frac, col = 'red', lwd = 3)
a <- 1
bval <- seq(0.1, 2, by = 0.1)
quants <- rep(NA, length(bval))
a <- 1
bval <- seq(0.1, 2, by = 0.1)
quants <- rep(NA, length(bval))
library(MCMCpack)
a <- 1
bval <- seq(0.1, 2, by = 0.1)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(10000, a, bval[bb]), probs = 0.99)
}
plot(bval, quants)
library(MCMCpack)
Nsims <- 50000
a <- 2
bval <- seq(0.1, 2, by = 0.1)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants)
library(MCMCpack)
Nsims <- 50000
a <- 2
bval <- seq(0.01, 1, by = 0.01)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants)
plot(bval, quants, type = 'l')
quantile(rnorm(1000), probs = 0.99)
quantile(rnorm(1000), probs = 0.01)
library(MCMCpack)
Nsims <- 50000
a <- 2
bval <- seq(0.01, 0.3, by = 0.01)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants, type = 'l')
library(MCMCpack)
Nsims <- 50000
a <- 2
bval <- seq(0.1, 0.2, length.out = 100)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants, type = 'l')
library(MCMCpack)
Nsims <- 50000
a <- 2
bval <- seq(0.12, 0.18, length.out = 50)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants, type = 'l')
library(MCMCpack)
Nsims <- 50000
a <- 2
bval <- seq(0.14, 0.15, length.out = 50)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants, type = 'l')
Nsims <- 100000
a <- 2
bval <- seq(0.14, 0.15, length.out = 20)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.99)
}
plot(bval, quants, type = 'l')
hist(rinvgamma(10000, a, 0.15))
hist(rinvgamma(10000, a, 0.15), breaks = 100, xlim = c(0, 5))
hist(rinvgamma(10000, a, 0.15), breaks = 1000, xlim = c(0, 5))
library(MCMCpack)
Nsims <- 100000
a <- 2
bval <- seq(0.1, 0.15, length.out = 20)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.95)
}
plot(bval, quants, type = 'l')
library(MCMCpack)
Nsims <- 100000
a <- 2
bval <- seq(0.1, 0.3, length.out = 20)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.95)
}
plot(bval, quants, type = 'l')
library(MCMCpack)
Nsims <- 100000
a <- 2
bval <- seq(0.3, 0.4, length.out = 20)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.95)
}
plot(bval, quants, type = 'l')
library(MCMCpack)
Nsims <- 100000
a <- 2
bval <- seq(0.35, 0.4, length.out = 20)
quants <- rep(NA, length(bval))
for (bb in 1 : length(bval)) {
quants[bb] <- quantile(rinvgamma(Nsims, a, bval[bb]), probs = 0.95)
}
plot(bval, quants, type = 'l')
dev.off()
rm(list = ls())
GetStartGammas <- function(Y, X, D, scaled = TRUE) {
sample_size <- dim(X)[1]
tensor_dim <- dim(X)[- 1]
if (length(tensor_dim) != 2) {
stop('Function only appropriate for K = 2.')
}
scaled_data <- ScaleData(Y = Y, X = X, scaled = scaled)
Y <- scaled_data$new_Y
X <- scaled_data$new_X
vecX <- array(X, dim = c(sample_size, prod(tensor_dim)))
las_mod <- cv.glmnet(x = vecX, y = Y - mean(Y))
las_mod <- glmnet(x = vecX, y = Y - mean(Y), lambda = las_mod$lambda.min)
las_beta <- array(las_mod$beta, dim = tensor_dim)
las_svd <- svd(las_beta)
G <- list(dim1 = las_svd$u[, 1 : D] %*% diag(sqrt(las_svd$d[1 : D])),
dim2 = las_svd$v[, 1 : D] %*% diag(sqrt(las_svd$d[1 : D])))
return(G)
}
dev.off()
rm(list = ls())
library(GIGrvg)
library(MCMCpack)
library(gplots)
library(glmnet)
source_path <- '~/Github/SofTeR/R/'
file.sources <- list.files(source_path, pattern="*function.R$")
sapply(paste0(source_path, file.sources), source, .GlobalEnv)
source('~/Documents/Research/Softer/Simulations/Data_specs/GenCoefTensor_function.R')
source('~/Documents/Research/Softer/Simulations/functions/myHeat_function.R')
wh_image <- 'dog'
Nsims <- 1000
burn <- 1500
thin <- 3
D <- 3
scaled <- TRUE
dev.off()
rm(list = ls())
library(GIGrvg)
library(MCMCpack)
library(gplots)
library(glmnet)
source_path <- '~/Github/SofTeR/R/'
file.sources <- list.files(source_path, pattern="*function.R$")
sapply(paste0(source_path, file.sources), source, .GlobalEnv)
source('~/Documents/Research/Softer/Simulations/Data_specs/GenCoefTensor_function.R')
source('~/Documents/Research/Softer/Simulations/functions/myHeat_function.R')
wh_image <- 'dog'
# -------- MCMC SPECIFICATIONS ------- #
Nsims <- 1000
burn <- 1500
thin <- 3
D <- 3
scaled <- TRUE
a_lambda <- 3
a_tau <- 3
b_sigma <- 3
alpha <- 1
Vstar <- 1
AVstar <- 0.1
hyper <- GetHyper(K = 2, D = D, Vstar = Vstar, AVstar = AVstar,
alpha = alpha, a_lambda = a_lambda, a_tau = a_tau,
a_sigma = a_sigma, include_C = TRUE)
priors <- list(sigma = c(a_sigma, hyper$b_sigma),
tau = c(0.001, 0.001),
alpha = c(0, 1),
tau_gamma = c(a_tau, hyper$b_tau),
lambda = c(a_lambda, hyper$b_lambda),
zeta = alpha)
rm(list = ls())
library(GIGrvg)
library(MCMCpack)
library(gplots)
library(glmnet)
source_path <- '~/Github/SofTeR/R/'
file.sources <- list.files(source_path, pattern="*function.R$")
sapply(paste0(source_path, file.sources), source, .GlobalEnv)
source('~/Documents/Research/Softer/Simulations/Data_specs/GenCoefTensor_function.R')
source('~/Documents/Research/Softer/Simulations/functions/myHeat_function.R')
wh_image <- 'dog'
# -------- MCMC SPECIFICATIONS ------- #
Nsims <- 1000
burn <- 1500
thin <- 3
D <- 3
scaled <- TRUE
a_lambda <- 3
a_tau <- 3
a_sigma <- 3
alpha <- 1
Vstar <- 1
AVstar <- 0.1
hyper <- GetHyper(K = 2, D = D, Vstar = Vstar, AVstar = AVstar,
alpha = alpha, a_lambda = a_lambda, a_tau = a_tau,
a_sigma = a_sigma, include_C = TRUE)
priors <- list(sigma = c(a_sigma, hyper$b_sigma),
tau = c(0.001, 0.001),
alpha = c(0, 1),
tau_gamma = c(a_tau, hyper$b_tau),
lambda = c(a_lambda, hyper$b_lambda),
zeta = alpha)
sample_size <- 500
true_alpha <- 1.5
true_tau <- 0.5
load(paste0('~/Documents/Research/Softer/Simulations/pictures/', wh_image,
'_binary.dat'))
true_B <- true_B[21 : 25, 21 : 25]
tensor_dim <- dim(true_B)
tensor_mode <- length(tensor_dim)
myHeat(true_B)
set.seed(31)
X <- array(rnorm(sample_size * prod(tensor_dim)),
dim = c(sample_size, tensor_dim))
true_meanY <- true_alpha + apply(X, 1, function(x) sum(x * true_B))
Y <- true_meanY + rnorm(sample_size, sd = sqrt(true_tau))
mle_x <- t(apply(X, 1, function(x) c(t(x))))
mle_mod <- lm(Y ~ mle_x)
mle_coef <- matrix(mle_mod$coef[- 1], nrow = tensor_dim[1],
ncol = tensor_dim[2], byrow = TRUE)
start_vals <- NULL
start_vals$Gammas <- GetStartGammas(Y = Y, X = X, D = D, scaled = scaled)
start_vals$sigma <- rep(0.0001, tensor_mode)
softer2d <- Softer2D(Y = Y, X = X, D = D, Nsims = Nsims, start_vals = start_vals,
priors = priors, scaled = scaled)
shorter <- BurnThin(softer2d, burn = burn, thin = thin)
burn
Nsims
burn = 500
thin = 5
shorter <- BurnThin(softer2d, burn = burn, thin = thin)
myHeat(true_B)
myHeat(shorter$mean_est_B)
myHeat(true_B - shorter$mean_est_B)
mean((true_B - shorter$mean_est_B) ^ 2)
median((true_B - shorter$mean_est_B) ^ 2)
plot(true_B, shorter$mean_est_B)
abline(a = 0, b = 1)
# (tau) Residual variance.
plot(shorter$res_var, type = 'l')
abline(h = true_tau, col = 'red', lwd = 2, lty = 2)
abline(h = summary(mle_mod)$sigma ^ 2, col = 'blue', lwd = 2, lty = 2)
# (alpha) Intercept.
plot(shorter$intercepts, type = 'l')
abline(h = true_alpha, col = 'red', lwd = 2, lty = 2)
abline(h = mle_mod$coef[1], col = 'blue', lwd = 2, lty = 2)
# (B_prod) Plotting the product of Bs.
p1 <- 1 : min(tensor_dim[1], 5)
p2 <- 1 : min(tensor_dim[2], 5)
par(mfrow = c(length(p1), length(p2)), mar = rep(1, 4))
for (j1 in p1) {
for (j2 in p2) {
plot(shorter$est_B[, j1, j2], type = 'l')
abline(h = true_B[j1, j2], col = 'red', lty = 2, lwd = 2)
abline(h = mle_coef[j1, j2], col = 'blue', lty = 2, lwd = 2)
}
}
names(shorter)
load('~/Documents/Research/Spatial_Confounding/Patrick_Schnell/Lucas_data/analysis_data_county2.dat')
setwd('~/Github/BAC/')
source('CalcLogLike_function.R')
source('LogPriorOdds_function.R')
source('UpdateAlphaX_function.R')
library(BAC)
install.packages('devtools')
library(devtools)
devtools::install_github("gpapadog/BAC")
library(BAC)
data(toyData)
laod(toyData)
data('toyData')
data('toyData')
ls()
library(BAC)
data('toyData')
library(devtools)
devtools::install_github("gpapadog/DAPSm")
library(DAPSm)
data('toyData')
source('~/Documents/Research/Functions/Package_function.R')
Package('~/Github/BAC')
library(BAC)
data("toyData")
head(toyData)
